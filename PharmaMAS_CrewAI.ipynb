{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dev-singh-chauhan/PharmaMAS_Project-/blob/main/PharmaMAS_CrewAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr_GK9GsS1Or",
        "outputId": "59844aa6-407c-4c3a-efd6-79bb3ae3c7c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-1.7.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.6-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.52.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: aiosqlite~=0.21.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (0.21.0)\n",
            "Collecting appdirs~=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting chromadb~=1.1.0 (from crewai)\n",
            "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting click~=8.1.7 (from crewai)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json-repair~=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.25.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting json5~=0.10.0 (from crewai)\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting jsonref~=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting mcp~=1.16.0 (from crewai)\n",
            "  Downloading mcp-1.16.0-py3-none-any.whl.metadata (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.83.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: openpyxl~=3.1.5 in /usr/local/lib/python3.12/dist-packages (from crewai) (3.1.5)\n",
            "Collecting opentelemetry-api~=1.34.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http~=1.34.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk~=1.34.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pdfplumber~=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker~=2.7.0 (from crewai)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pydantic-settings~=2.10.1 (from crewai)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pydantic~=2.11.9 (from crewai)\n",
            "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt~=2.9.0 (from crewai)\n",
            "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting regex~=2024.9.11 (from crewai)\n",
            "  Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers~=0.20.3 (from crewai)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tomli-w~=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli~=2.0.2 (from crewai)\n",
            "  Downloading tomli-2.0.2-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting uv~=0.9.13 (from crewai)\n",
            "  Downloading uv-0.9.18-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.3)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.4)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Collecting build>=1.0.3 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (3.11.5)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (13.9.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (3.13.2)\n",
            "Collecting diskcache>=5.6.3 (from instructor>=1.3.3->crewai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (0.17.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "INFO: pip is looking at multiple versions of instructor to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pre-commit>=4.3.0 (from instructor>=1.3.3->crewai)\n",
            "  Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (2.41.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.4.56)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.4.3)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (3.0.3)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.48.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl~=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api~=1.34.0->crewai) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk~=1.34.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pdfminer.six==20251107 (from pdfplumber~=0.11.4->crewai)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber~=0.11.4->crewai)\n",
            "  Downloading pypdfium2-5.2.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.9->crewai) (0.7.0)\n",
            "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor>=1.3.3->crewai)\n",
            "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.9->crewai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers~=0.20.3->crewai) (0.36.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.22.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.34.0->crewai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.0.0)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (1.14.0)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb~=1.1.0->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb~=1.1.0->crewai) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (15.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (2.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (4.9.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb~=1.1.0->crewai) (0.1.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai) (4.5.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (2.23)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (0.6.1)\n",
            "Downloading crewai-1.7.1-py3-none-any.whl (666 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m666.7/666.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.83.0-py3-none-any.whl (723 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m723.4/723.4 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading reportlab-4.4.6-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.52.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.12.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.9/157.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.0/352.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.25.3-py3-none-any.whl (12 kB)\n",
            "Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading mcp-1.16.0-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
            "Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (797 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.0/797.0 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading tomli_w-1.1.0-py3-none-any.whl (6.4 kB)\n",
            "Downloading uv-0.9.18-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.2.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=84701f8a4dc2f7b5239fb36ded9aebb15142078d40a793fbe9f95e3bb0797a54\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, distlib, appdirs, virtualenv, uvloop, uv, urllib3, tomli-w, tomli, reportlab, regex, python-dotenv, pyproject_hooks, pypdfium2, pyjwt, pydantic-core, pybase64, portalocker, opentelemetry-proto, nodeenv, mmh3, jsonref, json5, json-repair, jiter, identify, humanfriendly, httptools, diskcache, click, cfgv, bcrypt, backoff, watchfiles, pydeck, pydantic, pre-commit, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, pydantic-settings, posthog, pdfminer.six, opentelemetry-semantic-conventions, openai, onnxruntime, tokenizers, pdfplumber, opentelemetry-sdk, mcp, kubernetes, instructor, streamlit, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, chromadb, crewai\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.2.1\n",
            "    Uninstalling python-dotenv-1.2.1:\n",
            "      Successfully uninstalled python-dotenv-1.2.1\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.10.1\n",
            "    Uninstalling PyJWT-2.10.1:\n",
            "      Successfully uninstalled PyJWT-2.10.1\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.12.0\n",
            "    Uninstalling jiter-0.12.0:\n",
            "      Successfully uninstalled jiter-0.12.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: pydantic-settings\n",
            "    Found existing installation: pydantic-settings 2.12.0\n",
            "    Uninstalling pydantic-settings-2.12.0:\n",
            "      Successfully uninstalled pydantic-settings-2.12.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.9.0\n",
            "    Uninstalling openai-2.9.0:\n",
            "      Successfully uninstalled openai-2.9.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "  Attempting uninstall: mcp\n",
            "    Found existing installation: mcp 1.23.3\n",
            "    Uninstalling mcp-1.23.3:\n",
            "      Successfully uninstalled mcp-1.23.3\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-http\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-http 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-http-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-http-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.34.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-exporter-otlp-proto-http>=1.36.0, but you have opentelemetry-exporter-otlp-proto-http 1.34.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.34.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-api>=1.35.0, but you have opentelemetry-api 1.34.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.34.1 which is incompatible.\n",
            "transformers 4.57.3 requires tokenizers<=0.23.0,>=0.22.0, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cfgv-3.5.0 chromadb-1.1.1 click-8.1.8 coloredlogs-15.0.1 crewai-1.7.1 diskcache-5.6.3 distlib-0.4.0 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 identify-2.6.15 instructor-1.12.0 jiter-0.10.0 json-repair-0.25.3 json5-0.10.0 jsonref-1.1.0 kubernetes-34.1.0 mcp-1.16.0 mmh3-5.2.0 nodeenv-1.9.1 onnxruntime-1.23.2 openai-1.83.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-exporter-otlp-proto-http-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 pdfminer.six-20251107 pdfplumber-0.11.8 portalocker-2.7.0 posthog-5.4.0 pre-commit-4.5.1 pybase64-1.4.3 pydantic-2.11.10 pydantic-core-2.33.2 pydantic-settings-2.10.1 pydeck-0.9.1 pyjwt-2.9.0 pypdfium2-5.2.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.1 regex-2024.9.11 reportlab-4.4.6 streamlit-1.52.1 tokenizers-0.20.3 tomli-2.0.2 tomli-w-1.1.0 urllib3-2.3.0 uv-0.9.18 uvloop-0.22.1 virtualenv-20.35.4 watchfiles-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install crewai openai langchain pandas reportlab streamlit python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 1: install required packages\n",
        "!pip install --upgrade pip\n",
        "# Try installing crewai; if it doesn't exist on pip, we attempted to provide a GitHub fallback.\n",
        "# If crewai is unavailable, the notebook will automatically use fallback local agent classes.\n",
        "!pip install crewai openai langchain pandas reportlab python-dotenv xlrd openpyxl --quiet || true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4LJUioWTB5g",
        "outputId": "88952ca4-ceaa-44cd-9838-a0ec11b7d5d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2: set API key env var (use real key only if needed)\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Use the Secrets Manager to store your API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# IMPORTANT: crewai requires OPENAI_API_KEY for OpenAI models.\n",
        "# Try to get OPENAI_API_KEY from secrets, fall back to GOOGLE_API_KEY if not found.\n",
        "try:\n",
        "    openai_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "except Exception:\n",
        "    openai_key = None\n",
        "\n",
        "if not openai_key:\n",
        "    openai_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "\n",
        "# Set a default model name as well, often needed by libraries\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = \"gpt-4o-mini\" # Or another suitable model name\n",
        "print(\"OPENAI_API_KEY and OPENAI_MODEL_NAME set from secrets/defaults.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKIIvIyXTTdP",
        "outputId": "599481e7-bbee-462b-a067-25617299bb78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY and OPENAI_MODEL_NAME set from secrets/defaults.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 3: create folder structure and write mock JSON/CSV data\n",
        "import os, json, csv\n",
        "\n",
        "BASE = \"/content/pharma_mas\"\n",
        "os.makedirs(BASE, exist_ok=True)\n",
        "os.makedirs(os.path.join(BASE, \"agents\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(BASE, \"crew\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(BASE, \"mock_data\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(BASE, \"reports\"), exist_ok=True)\n",
        "\n",
        "# IQVIA mock data (market)\n",
        "iqvia_mock = [\n",
        "    {\"molecule\": \"Metformin\", \"therapy\": \"Diabetes\", \"market_size_usd_b\": 4.5, \"cagr_percent\": 6.1,\n",
        "     \"top_competitors\": [\"Cipla\", \"Lupin\", \"Sun Pharma\"]},\n",
        "    {\"molecule\": \"Aspirin\", \"therapy\": \"Cardiovascular\", \"market_size_usd_b\": 2.1, \"cagr_percent\": 2.0,\n",
        "     \"top_competitors\": [\"Bayer\", \"Cipla\"]}\n",
        "]\n",
        "with open(os.path.join(BASE, \"mock_data\", \"iqvia_mock.json\"), \"w\") as f:\n",
        "    json.dump(iqvia_mock, f, indent=2)\n",
        "\n",
        "# Patent mock\n",
        "patent_mock = [\n",
        "    {\"molecule\": \"Metformin\", \"patents\": [\n",
        "        {\"id\": \"US12345\", \"title\": \"Metformin for Diabetes\", \"expiry_year\": 2028, \"status\": \"Active\"},\n",
        "        {\"id\": \"US67890\", \"title\": \"Metformin use in oncology\", \"expiry_year\": 2022, \"status\": \"Expired\"}\n",
        "    ]},\n",
        "    {\"molecule\": \"Aspirin\", \"patents\": [\n",
        "        {\"id\": \"US54321\", \"title\": \"Aspirin formulation\", \"expiry_year\": 2030, \"status\": \"Active\"}\n",
        "    ]}\n",
        "]\n",
        "with open(os.path.join(BASE, \"mock_data\", \"patent_mock.json\"), \"w\") as f:\n",
        "    json.dump(patent_mock, f, indent=2)\n",
        "\n",
        "# Clinical trials mock\n",
        "clinical_mock = [\n",
        "    {\"molecule\": \"Metformin\", \"trials\": [\n",
        "        {\"id\": \"CT-001\", \"phase\": \"Phase II\", \"condition\": \"Obesity\", \"status\": \"Recruiting\", \"sponsor\": \"Uni A\"},\n",
        "        {\"id\": \"CT-002\", \"phase\": \"Phase III\", \"condition\": \"PCOS\", \"status\": \"Completed\", \"sponsor\": \"Uni B\"}\n",
        "    ]},\n",
        "    {\"molecule\": \"Aspirin\", \"trials\": [\n",
        "        {\"id\": \"CT-003\", \"phase\": \"Phase IV\", \"condition\": \"Cardiovascular\", \"status\": \"Active\", \"sponsor\": \"PharmaX\"}\n",
        "    ]}\n",
        "]\n",
        "with open(os.path.join(BASE, \"mock_data\", \"clinical_mock.json\"), \"w\") as f:\n",
        "    json.dump(clinical_mock, f, indent=2)\n",
        "\n",
        "# EXIM (CSV)\n",
        "exim_rows = [\n",
        "    [\"molecule\", \"year\", \"export_value_usd_m\", \"import_value_usd_m\", \"top_dest_country\"],\n",
        "    [\"Metformin\", \"2023\", \"50\", \"10\", \"USA\"],\n",
        "    [\"Metformin\", \"2022\", \"45\", \"8\", \"USA\"],\n",
        "    [\"Aspirin\", \"2023\", \"30\", \"12\", \"GER\"]\n",
        "]\n",
        "with open(os.path.join(BASE, \"mock_data\", \"exim_mock.csv\"), \"w\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(exim_rows)\n",
        "\n",
        "# Web mock (scientific summaries)\n",
        "web_mock = [\n",
        "    {\"molecule\": \"Metformin\", \"articles\": [\n",
        "        {\"title\": \"Metformin shows promise in cancer models\", \"source\": \"Journal A\", \"year\": 2023,\n",
        "         \"summary\": \"Preclinical studies show anti-proliferative effects.\"},\n",
        "        {\"title\": \"Metformin and longevity\", \"source\": \"Journal B\", \"year\": 2022,\n",
        "         \"summary\": \"Association studies indicate potential life extension benefits.\"}\n",
        "    ]},\n",
        "    {\"molecule\": \"Aspirin\", \"articles\": [\n",
        "        {\"title\": \"Aspirin low-dose study\", \"source\": \"Journal C\", \"year\": 2021, \"summary\": \"Cardio-protective effects observed.\"}\n",
        "    ]}\n",
        "]\n",
        "with open(os.path.join(BASE, \"mock_data\", \"web_mock.json\"), \"w\") as f:\n",
        "    json.dump(web_mock, f, indent=2)\n",
        "\n",
        "print(\"Mock data created at:\", os.path.join(BASE, \"mock_data\"))\n"
      ],
      "metadata": {
        "id": "XXP1xMn8TlUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2b763a-834e-461a-a155-a797171b666d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mock data created at: /content/pharma_mas/mock_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f84c6ae",
        "outputId": "8249b411-5aca-46f0-8039-0ba6d869faf3"
      },
      "source": [
        "# Colab cell 4: force use of fallback classes to bypass CrewAI/OpenAI\n",
        "USE_CREWAI = False\n",
        "\n",
        "# Fallback: Implement minimal Agent/Task/Crew classes for orchestration\n",
        "print(\"CrewAI not available; using local fallback agents as requested.\")\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Minimal local Agent representation (for clarity)\n",
        "class Agent:\n",
        "    def __init__(self, role, goal, backstory=None, verbose=False):\n",
        "        self.role = role\n",
        "        self.goal = goal\n",
        "        self.backstory = backstory\n",
        "        self.verbose = verbose\n",
        "    def run(self, input_data):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Task:\n",
        "    def __init__(self, description, agent, func=None, expected_output=None, name=None):\n",
        "        self.description = description\n",
        "        self.agent = agent\n",
        "        self.func = func  # optional function to call\n",
        "        self.expected_output = expected_output # CrewAI compatibility\n",
        "        self.name = name if name else description # Use name if provided, else description\n",
        "\n",
        "class Crew:\n",
        "    def __init__(self, agents, tasks, verbose=False):\n",
        "        self.agents = agents\n",
        "        self.tasks = tasks\n",
        "        self.verbose = verbose\n",
        "    def run(self, input_data):\n",
        "        # run each task with a threadpool; tasks have agent.func to execute\n",
        "        results = {}\n",
        "        with ThreadPoolExecutor(max_workers=len(self.tasks)) as ex:\n",
        "            futures = {}\n",
        "            for t in self.tasks:\n",
        "                if t.func is None:\n",
        "                    continue\n",
        "                # For fallback, we'll store results by task name\n",
        "                futures[ex.submit(t.func, input_data)] = t.name\n",
        "            for fut in as_completed(futures):\n",
        "                task_name = futures[fut]\n",
        "                try:\n",
        "                    results[task_name] = fut.result()\n",
        "                except Exception as e:\n",
        "                    results[task_name] = {\"error\": str(e)}\n",
        "        return results\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CrewAI not available; using local fallback agents as requested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 5: worker functions that act like Worker Agents\n",
        "import json, pandas as pd\n",
        "DATA_DIR = os.path.join(BASE, \"mock_data\")\n",
        "\n",
        "def market_worker(input_data):\n",
        "    molecule = input_data.get(\"molecule\")\n",
        "    with open(os.path.join(DATA_DIR, \"iqvia_mock.json\")) as f:\n",
        "        iq = json.load(f)\n",
        "    recs = [r for r in iq if r[\"molecule\"].lower() == molecule.lower()]\n",
        "    if not recs:\n",
        "        return {\"market\": None, \"note\": \"No market mock data found\"}\n",
        "    return {\"market\": recs[0]}\n",
        "\n",
        "def patent_worker(input_data):\n",
        "    molecule = input_data.get(\"molecule\")\n",
        "    with open(os.path.join(DATA_DIR, \"patent_mock.json\")) as f:\n",
        "        pt = json.load(f)\n",
        "    recs = [r for r in pt if r[\"molecule\"].lower() == molecule.lower()]\n",
        "    if not recs:\n",
        "        return {\"patents\": [], \"note\": \"No patent mock data found\"}\n",
        "    return {\"patents\": recs[0][\"patents\"]}\n",
        "\n",
        "def clinical_worker(input_data):\n",
        "    molecule = input_data.get(\"molecule\")\n",
        "    with open(os.path.join(DATA_DIR, \"clinical_mock.json\")) as f:\n",
        "        ct = json.load(f)\n",
        "    recs = [r for r in ct if r[\"molecule\"].lower() == molecule.lower()]\n",
        "    if not recs:\n",
        "        return {\"trials\": [], \"note\": \"No clinical mock data found\"}\n",
        "    return {\"trials\": recs[0][\"trials\"]}\n",
        "\n",
        "def exim_worker(input_data):\n",
        "    molecule = input_data.get(\"molecule\")\n",
        "    df = pd.read_csv(os.path.join(DATA_DIR, \"exim_mock.csv\"))\n",
        "    md = df[df[\"molecule\"].str.lower() == molecule.lower()]\n",
        "    if md.empty:\n",
        "        return {\"exim\": [], \"note\": \"No EXIM mock data found\"}\n",
        "    # aggregate by year\n",
        "    rows = md.to_dict(orient=\"records\")\n",
        "    return {\"exim\": rows}\n",
        "\n",
        "def web_worker(input_data):\n",
        "    molecule = input_data.get(\"molecule\")\n",
        "    with open(os.path.join(DATA_DIR, \"web_mock.json\")) as f:\n",
        "        web = json.load(f)\n",
        "    recs = [r for r in web if r[\"molecule\"].lower() == molecule.lower()]\n",
        "    if not recs:\n",
        "        return {\"articles\": [], \"note\": \"No web mock data found\"}\n",
        "    return {\"articles\": recs[0][\"articles\"]}\n",
        "\n",
        "def internal_worker(input_data):\n",
        "    # Simulated internal doc summary (we have no real PDFs here) - return a static insight to mimic parsing\n",
        "    molecule = input_data.get(\"molecule\")\n",
        "    insights = {\n",
        "        \"Metformin\": \"Internal field reports indicate interest in metabolic effects and off-label research collaboration.\",\n",
        "        \"Aspirin\": \"Internal sales teams report stable volumes for cardiovascular segment.\"\n",
        "    }\n",
        "    return {\"internal_insight\": insights.get(molecule, \"No internal insight found\")}\n"
      ],
      "metadata": {
        "id": "1V-6GyV62B0z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47383c66",
        "outputId": "ec452ea8-ecb0-46fc-a6f4-55f829dc21be"
      },
      "source": [
        "# Colab cell 6: construct agents/tasks and the crew\n",
        "# Create Agent objects (either real CrewAI Agent or fallback Agent)\n",
        "market_agent = Agent(role=\"Market Analyst\", goal=\"Analyze market mock data\", backstory=\"Expert in analyzing market trends and data.\", verbose=True)\n",
        "patent_agent = Agent(role=\"Patent Specialist\", goal=\"Summarize patent mock data\", backstory=\"Skilled in reviewing and summarizing patent information.\", verbose=True)\n",
        "clinical_agent = Agent(role=\"Clinical Trials Analyst\", goal=\"Summarize clinical trials\", backstory=\"Experienced in analyzing clinical trial data and results.\", verbose=True)\n",
        "exim_agent = Agent(role=\"Trade Analyst\", goal=\"Summarize trade data\", backstory=\"Knowledgeable in import and export data analysis.\", verbose=True)\n",
        "web_agent = Agent(role=\"Web Intelligence\", goal=\"Summarize web articles and signals\", backstory=\"Adept at gathering and summarizing information from the web.\", verbose=True)\n",
        "internal_agent = Agent(role=\"Internal Knowledge\", goal=\"Summarize internal docs\", backstory=\"Accesses and summarizes internal company documents and insights.\", verbose=True)\n",
        "\n",
        "# Build Tasks - each Task holds a description, agent, and function to run\n",
        "market_task = Task(name=\"market\", description=\"Analyze the provided market data for the given molecule and summarize key findings including market size, growth rate, and top competitors.\", agent=market_agent, func=market_worker, expected_output=\"A summary of the market data for the specified molecule, including market size, CAGR, and key competitors.\")\n",
        "patent_task = Task(name=\"patents\", description=\"Review and summarize the patent data for the given molecule, noting active and expired patents and their key details.\", agent=patent_agent, func=patent_worker, expected_output=\"A summary of the patent information for the molecule, detailing active/expired status and relevant details for each patent.\")\n",
        "clinical_task = Task(name=\"clinical\", description=\"Analyze the clinical trial data for the given molecule and provide a summary of ongoing and completed trials, including phase, condition, and sponsor.\", agent=clinical_agent, func=clinical_worker, expected_output=\"A summary of clinical trials for the molecule, including phases, conditions, and sponsors.\")\n",
        "exim_task = Task(name=\"exim\", description=\"Review the export and import data for the given molecule and summarize the key trade flows and top destinations.\", agent=exim_agent, func=exim_worker, expected_output=\"A summary of export and import data for the molecule, including trade values and top destination countries.\")\n",
        "web_task = Task(name=\"web\", description=\"Gather and summarize key insights from web articles and scientific summaries related to the given molecule.\", agent=web_agent, func=web_worker, expected_output=\"A summary of key findings and insights from web articles and scientific literature about the molecule.\")\n",
        "internal_task = Task(name=\"internal\", description=\"Summarize any relevant internal company insights or documents related to the given molecule.\", agent=internal_agent, func=internal_worker, expected_output=\"A summary of internal company knowledge or insights pertaining to the molecule.\")\n",
        "\n",
        "# Assemble the Crew\n",
        "pharma_crew = Crew(\n",
        "    agents=[market_agent, patent_agent, clinical_agent, exim_agent, web_agent, internal_agent],\n",
        "    tasks=[market_task, patent_task, clinical_task, exim_task, web_task, internal_task],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Crew and tasks ready.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crew and tasks ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b47cecf",
        "outputId": "93caf28b-ce93-4b10-e987-5fff9d4f4814"
      },
      "source": [
        "# Colab cell 7: Master Agent - orchestrates run and synthesizes summary\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import pprint\n",
        "\n",
        "def master_run(molecule):\n",
        "    input_data = {\"molecule\": molecule}\n",
        "    # Run crew (which runs all task functions concurrently in fallback)\n",
        "    # Use kickoff for CrewAI\n",
        "    if USE_CREWAI:\n",
        "        results = pharma_crew.kickoff(inputs=input_data)\n",
        "    else:\n",
        "        results = pharma_crew.run(input_data)\n",
        "\n",
        "\n",
        "    # results keys are task descriptions; unify into structured summary\n",
        "    summary = {\"molecule\": molecule, \"timestamp\": datetime.utcnow().isoformat()}\n",
        "    # map known task keys\n",
        "    # Note: CrewAI kickoff returns a single string output, not a dictionary of task results like the fallback\n",
        "    # We need to parse the CrewAI output or adjust the fallback for consistency if needed for further processing.\n",
        "    # For now, let's just include the raw output from CrewAI or the structured results from fallback.\n",
        "\n",
        "    if USE_CREWAI:\n",
        "        summary[\"raw_crew_output\"] = results\n",
        "        # If further structured processing is needed, we would need an agent to parse the 'results' string\n",
        "        # and extract structured information.\n",
        "    else:\n",
        "        # Access results using the new 'name' attribute of the tasks\n",
        "        summary[\"market\"] = results.get(\"market\", {})\n",
        "        summary[\"patents\"] = results.get(\"patents\", {})\n",
        "        summary[\"clinical\"] = results.get(\"clinical\", {})\n",
        "        summary[\"exim\"] = results.get(\"exim\", {})\n",
        "        summary[\"web\"] = results.get(\"web\", {})\n",
        "        summary[\"internal\"] = results.get(\"internal\", {})\n",
        "\n",
        "        # Simple heuristic to flag repurposing opportunity (only applies to fallback structured output):\n",
        "        # - If clinical trials exist outside main therapy (e.g., Metformin in cancer), or\n",
        "        # - If patents expired and market size indicates opportunity.\n",
        "        flags = []\n",
        "        try:\n",
        "            # check web articles for off-label signals\n",
        "            articles = summary[\"web\"].get(\"articles\", [])\n",
        "            off_label_hits = [a for a in articles if any(word in a[\"title\"].lower() for word in [\"cancer\",\"longevity\",\"aging\",\"oncology\"])]\n",
        "            if off_label_hits:\n",
        "                flags.append(\"Off-label scientific signal (web articles)\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            patents = summary[\"patents\"].get(\"patents\", [])\n",
        "            expired = [p for p in patents if p.get(\"status\",\" confined\").lower() == \"expired\" or p.get(\"expiry_year\",9999) <= datetime.utcnow().year]\n",
        "            if expired:\n",
        "                flags.append(\"Expired patents — potential freedom to operate\")\n",
        "        except Exception:\n",
        "            flags.append(\"Error processing patent data for flags\")\n",
        "        try:\n",
        "            market = summary[\"market\"].get(\"market\")\n",
        "            if market and market.get(\"market_size_usd_b\",0) > 1:\n",
        "                flags.append(\"Large therapy market (> $1B) — commercial interest\")\n",
        "        except Exception:\n",
        "            flags.append(\"Error processing market data for flags\")\n",
        "\n",
        "        summary[\"repurposing_flags\"] = flags or [\"No strong flags from mock data\"]\n",
        "\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Test run\n",
        "demo = master_run(\"Metformin\")\n",
        "pprint.pprint(demo)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'clinical': {'trials': [{'condition': 'Obesity',\n",
            "                          'id': 'CT-001',\n",
            "                          'phase': 'Phase II',\n",
            "                          'sponsor': 'Uni A',\n",
            "                          'status': 'Recruiting'},\n",
            "                         {'condition': 'PCOS',\n",
            "                          'id': 'CT-002',\n",
            "                          'phase': 'Phase III',\n",
            "                          'sponsor': 'Uni B',\n",
            "                          'status': 'Completed'}]},\n",
            " 'exim': {'exim': [{'export_value_usd_m': 50,\n",
            "                    'import_value_usd_m': 10,\n",
            "                    'molecule': 'Metformin',\n",
            "                    'top_dest_country': 'USA',\n",
            "                    'year': 2023},\n",
            "                   {'export_value_usd_m': 45,\n",
            "                    'import_value_usd_m': 8,\n",
            "                    'molecule': 'Metformin',\n",
            "                    'top_dest_country': 'USA',\n",
            "                    'year': 2022}]},\n",
            " 'internal': {'internal_insight': 'Internal field reports indicate interest in '\n",
            "                                  'metabolic effects and off-label research '\n",
            "                                  'collaboration.'},\n",
            " 'market': {'market': {'cagr_percent': 6.1,\n",
            "                       'market_size_usd_b': 4.5,\n",
            "                       'molecule': 'Metformin',\n",
            "                       'therapy': 'Diabetes',\n",
            "                       'top_competitors': ['Cipla', 'Lupin', 'Sun Pharma']}},\n",
            " 'molecule': 'Metformin',\n",
            " 'patents': {'patents': [{'expiry_year': 2028,\n",
            "                          'id': 'US12345',\n",
            "                          'status': 'Active',\n",
            "                          'title': 'Metformin for Diabetes'},\n",
            "                         {'expiry_year': 2022,\n",
            "                          'id': 'US67890',\n",
            "                          'status': 'Expired',\n",
            "                          'title': 'Metformin use in oncology'}]},\n",
            " 'repurposing_flags': ['Off-label scientific signal (web articles)',\n",
            "                       'Expired patents — potential freedom to operate',\n",
            "                       'Large therapy market (> $1B) — commercial interest'],\n",
            " 'timestamp': '2025-12-17T10:37:02.790859',\n",
            " 'web': {'articles': [{'source': 'Journal A',\n",
            "                       'summary': 'Preclinical studies show anti-proliferative '\n",
            "                                  'effects.',\n",
            "                       'title': 'Metformin shows promise in cancer models',\n",
            "                       'year': 2023},\n",
            "                      {'source': 'Journal B',\n",
            "                       'summary': 'Association studies indicate potential life '\n",
            "                                  'extension benefits.',\n",
            "                       'title': 'Metformin and longevity',\n",
            "                       'year': 2022}]}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2161534846.py:17: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  summary = {\"molecule\": molecule, \"timestamp\": datetime.utcnow().isoformat()}\n",
            "/tmp/ipython-input-2161534846.py:50: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  expired = [p for p in patents if p.get(\"status\",\" confined\").lower() == \"expired\" or p.get(\"expiry_year\",9999) <= datetime.utcnow().year]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 8: generate a PDF report and an Excel summary from the synthesized summary\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def generate_pdf_report(summary, out_path):\n",
        "    styles = getSampleStyleSheet()\n",
        "    doc = SimpleDocTemplate(out_path)\n",
        "    story = []\n",
        "    story.append(Paragraph(f\"Drug Repurposing Report - {summary['molecule']}\", styles[\"Heading1\"]))\n",
        "    story.append(Paragraph(f\"Generated: {summary['timestamp']}\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "    # Market\n",
        "    market = summary.get(\"market\", {}).get(\"market\")\n",
        "    story.append(Paragraph(\"Market Summary:\", styles[\"Heading2\"]))\n",
        "    if market:\n",
        "        md = [\n",
        "            [\"Therapy\", market.get(\"therapy\")],\n",
        "            [\"Market Size (USD B)\", str(market.get(\"market_size_usd_b\"))],\n",
        "            [\"CAGR (%)\", str(market.get(\"cagr_percent\"))],\n",
        "            [\"Top Competitors\", \", \".join(market.get(\"top_competitors\", []))]\n",
        "        ]\n",
        "        story.append(Table(md))\n",
        "    else:\n",
        "        story.append(Paragraph(\"No market data available.\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "\n",
        "    # Patents\n",
        "    story.append(Paragraph(\"Patent Summary:\", styles[\"Heading2\"]))\n",
        "    patents = summary.get(\"patents\", {}).get(\"patents\", [])\n",
        "    if patents:\n",
        "        p_rows = [[\"Patent ID\", \"Title\", \"Expiry Year\", \"Status\"]]\n",
        "        for p in patents:\n",
        "            p_rows.append([p.get(\"id\"), p.get(\"title\"), str(p.get(\"expiry_year\")), p.get(\"status\")])\n",
        "        story.append(Table(p_rows))\n",
        "    else:\n",
        "        story.append(Paragraph(\"No patents found.\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "\n",
        "    # Clinical\n",
        "    story.append(Paragraph(\"Clinical Trials Summary:\", styles[\"Heading2\"]))\n",
        "    trials = summary.get(\"clinical\", {}).get(\"trials\", [])\n",
        "    if trials:\n",
        "        t_rows = [[\"Trial ID\", \"Phase\", \"Condition\", \"Status\", \"Sponsor\"]]\n",
        "        for t in trials:\n",
        "            t_rows.append([t.get(\"id\"), t.get(\"phase\"), t.get(\"condition\"), t.get(\"status\"), t.get(\"sponsor\")])\n",
        "        story.append(Table(t_rows))\n",
        "    else:\n",
        "        story.append(Paragraph(\"No clinical trial data found.\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "\n",
        "    # Web + internal insights + flags\n",
        "    story.append(Paragraph(\"Web Insights (top article titles):\", styles[\"Heading2\"]))\n",
        "    articles = summary.get(\"web\", {}).get(\"articles\", [])\n",
        "    if articles:\n",
        "        for a in articles:\n",
        "            story.append(Paragraph(f\"- {a['title']} ({a['source']}, {a['year']}): {a['summary']}\", styles[\"Normal\"]))\n",
        "    else:\n",
        "        story.append(Paragraph(\"No web articles found.\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "\n",
        "    story.append(Paragraph(\"Internal Insight:\", styles[\"Heading2\"]))\n",
        "    story.append(Paragraph(summary.get(\"internal\", {}).get(\"internal_insight\", \"No internal insight\"), styles[\"Normal\"]))\n",
        "    story.append(Spacer(1,12))\n",
        "\n",
        "    story.append(Paragraph(\"Repurposing Flags / Heuristics:\", styles[\"Heading2\"]))\n",
        "    for f in summary.get(\"repurposing_flags\", []):\n",
        "        story.append(Paragraph(f\"- {f}\", styles[\"Normal\"]))\n",
        "\n",
        "    doc.build(story)\n",
        "    return out_path\n",
        "\n",
        "def generate_excel_summary(summary, out_path):\n",
        "    # Flatten the summary into multiple sheets\n",
        "    writer = pd.ExcelWriter(out_path, engine=\"openpyxl\")\n",
        "    # Market\n",
        "    market = summary.get(\"market\", {}).get(\"market\")\n",
        "    if market:\n",
        "        pd.DataFrame([market]).to_excel(writer, sheet_name=\"Market\", index=False)\n",
        "    else:\n",
        "        pd.DataFrame([{}]).to_excel(writer, sheet_name=\"Market\", index=False)\n",
        "    # Patents\n",
        "    patents = summary.get(\"patents\", {}).get(\"patents\", [])\n",
        "    pd.DataFrame(patents).to_excel(writer, sheet_name=\"Patents\", index=False)\n",
        "    # Clinical\n",
        "    trials = summary.get(\"clinical\", {}).get(\"trials\", [])\n",
        "    pd.DataFrame(trials).to_excel(writer, sheet_name=\"Clinical\", index=False)\n",
        "    # EXIM\n",
        "    exim = summary.get(\"exim\", {}).get(\"exim\", [])\n",
        "    pd.DataFrame(exim).to_excel(writer, sheet_name=\"EXIM\", index=False)\n",
        "    # Web\n",
        "    articles = summary.get(\"web\", {}).get(\"articles\", [])\n",
        "    pd.DataFrame(articles).to_excel(writer, sheet_name=\"Web\", index=False)\n",
        "    # Flags & internal\n",
        "    pd.DataFrame({\"flags\": summary.get(\"repurposing_flags\", [])}).to_excel(writer, sheet_name=\"Flags\", index=False)\n",
        "    pd.DataFrame([{\"internal\": summary.get(\"internal\", {}).get(\"internal_insight\", \"\")}]).to_excel(writer, sheet_name=\"Internal\", index=False)\n",
        "\n",
        "    writer.close()\n",
        "    return out_path\n",
        "\n",
        "# Generate files for demo summary\n",
        "demo_summary = demo  # from earlier master_run example\n",
        "pdf_path = os.path.join(BASE, \"reports\", f\"{demo_summary['molecule']}_Report.pdf\")\n",
        "xlsx_path = os.path.join(BASE, \"reports\", f\"{demo_summary['molecule']}_Summary.xlsx\")\n",
        "\n",
        "generate_pdf_report(demo_summary, pdf_path)\n",
        "generate_excel_summary(demo_summary, xlsx_path)\n",
        "print(\"Report files created:\")\n",
        "print(pdf_path)\n",
        "print(xlsx_path)\n"
      ],
      "metadata": {
        "id": "3hihbo4uU2CK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7c2583-31c6-4861-8865-7576d48642a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report files created:\n",
            "/content/pharma_mas/reports/Metformin_Report.pdf\n",
            "/content/pharma_mas/reports/Metformin_Summary.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 9: show final summary and provide download link (Colab environment)\n",
        "import json, os\n",
        "from IPython.display import FileLink, display\n",
        "\n",
        "# Show summary\n",
        "print(\"Final summary (pretty):\")\n",
        "import pprint\n",
        "pprint.pprint(demo_summary)\n",
        "\n",
        "# Provide download links to the generated files\n",
        "display(FileLink(pdf_path))\n",
        "display(FileLink(xlsx_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "_ns5KC39I_wW",
        "outputId": "77e410e8-f2d5-44d4-9c38-4227c7aae2e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final summary (pretty):\n",
            "{'clinical': {'trials': [{'condition': 'Obesity',\n",
            "                          'id': 'CT-001',\n",
            "                          'phase': 'Phase II',\n",
            "                          'sponsor': 'Uni A',\n",
            "                          'status': 'Recruiting'},\n",
            "                         {'condition': 'PCOS',\n",
            "                          'id': 'CT-002',\n",
            "                          'phase': 'Phase III',\n",
            "                          'sponsor': 'Uni B',\n",
            "                          'status': 'Completed'}]},\n",
            " 'exim': {'exim': [{'export_value_usd_m': 50,\n",
            "                    'import_value_usd_m': 10,\n",
            "                    'molecule': 'Metformin',\n",
            "                    'top_dest_country': 'USA',\n",
            "                    'year': 2023},\n",
            "                   {'export_value_usd_m': 45,\n",
            "                    'import_value_usd_m': 8,\n",
            "                    'molecule': 'Metformin',\n",
            "                    'top_dest_country': 'USA',\n",
            "                    'year': 2022}]},\n",
            " 'internal': {'internal_insight': 'Internal field reports indicate interest in '\n",
            "                                  'metabolic effects and off-label research '\n",
            "                                  'collaboration.'},\n",
            " 'market': {'market': {'cagr_percent': 6.1,\n",
            "                       'market_size_usd_b': 4.5,\n",
            "                       'molecule': 'Metformin',\n",
            "                       'therapy': 'Diabetes',\n",
            "                       'top_competitors': ['Cipla', 'Lupin', 'Sun Pharma']}},\n",
            " 'molecule': 'Metformin',\n",
            " 'patents': {'patents': [{'expiry_year': 2028,\n",
            "                          'id': 'US12345',\n",
            "                          'status': 'Active',\n",
            "                          'title': 'Metformin for Diabetes'},\n",
            "                         {'expiry_year': 2022,\n",
            "                          'id': 'US67890',\n",
            "                          'status': 'Expired',\n",
            "                          'title': 'Metformin use in oncology'}]},\n",
            " 'repurposing_flags': ['Off-label scientific signal (web articles)',\n",
            "                       'Expired patents — potential freedom to operate',\n",
            "                       'Large therapy market (> $1B) — commercial interest'],\n",
            " 'timestamp': '2025-12-15T16:56:49.086997',\n",
            " 'web': {'articles': [{'source': 'Journal A',\n",
            "                       'summary': 'Preclinical studies show anti-proliferative '\n",
            "                                  'effects.',\n",
            "                       'title': 'Metformin shows promise in cancer models',\n",
            "                       'year': 2023},\n",
            "                      {'source': 'Journal B',\n",
            "                       'summary': 'Association studies indicate potential life '\n",
            "                                  'extension benefits.',\n",
            "                       'title': 'Metformin and longevity',\n",
            "                       'year': 2022}]}}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/pharma_mas/reports/Metformin_Report.pdf"
            ],
            "text/html": [
              "<a href='/content/pharma_mas/reports/Metformin_Report.pdf' target='_blank'>/content/pharma_mas/reports/Metformin_Report.pdf</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/pharma_mas/reports/Metformin_Summary.xlsx"
            ],
            "text/html": [
              "<a href='/content/pharma_mas/reports/Metformin_Summary.xlsx' target='_blank'>/content/pharma_mas/reports/Metformin_Summary.xlsx</a><br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0587affc",
        "outputId": "07ed31a7-50c7-47a5-8bf5-fc68a39f8616"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Trigger download for the PDF file\n",
        "files.download(pdf_path)\n",
        "print(f\"Downloading {pdf_path}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e81af7e8-c309-4f7a-bc3f-afd39b65fb26\", \"Metformin_Report.pdf\", 2739)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /content/pharma_mas/reports/Metformin_Report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "61b86a12",
        "outputId": "2e0a4113-0760-4f48-f8f2-ebb8c4076cbb"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Trigger download for the Excel file\n",
        "files.download(xlsx_path)\n",
        "print(f\"Downloading {xlsx_path}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_72ec6b0a-a4fe-412c-a720-790a16558875\", \"Aspirin_Summary.xlsx\", 8361)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /content/pharma_mas/reports/Aspirin_Summary.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gChMMcOtLz9Y",
        "outputId": "1f3e9453-33bc-42e6-b3fa-178a3cfd88b0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-15 18:07:58--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.11.1/cloudflared-linux-amd64.deb [following]\n",
            "--2025-12-15 18:07:58--  https://github.com/cloudflare/cloudflared/releases/download/2025.11.1/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/106867604/8a32f7c6-649c-4f0d-806d-e14c19d0786d?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-15T18%3A52%3A06Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64.deb&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-15T17%3A51%3A19Z&ske=2025-12-15T18%3A52%3A06Z&sks=b&skv=2018-11-09&sig=xrW83qHdAt9HacNPGblLq6oiiLKLtiUh8JwRMPA7gpk%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTgyMzg3OCwibmJmIjoxNzY1ODIyMDc4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.D3T6TSFtgmWi7HfsG0uOcLhypUO1MWkiCTy559GJRVU&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-15 18:07:58--  https://release-assets.githubusercontent.com/github-production-release-asset/106867604/8a32f7c6-649c-4f0d-806d-e14c19d0786d?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-15T18%3A52%3A06Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64.deb&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-15T17%3A51%3A19Z&ske=2025-12-15T18%3A52%3A06Z&sks=b&skv=2018-11-09&sig=xrW83qHdAt9HacNPGblLq6oiiLKLtiUh8JwRMPA7gpk%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTgyMzg3OCwibmJmIjoxNzY1ODIyMDc4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.D3T6TSFtgmWi7HfsG0uOcLhypUO1MWkiCTy559GJRVU&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20192500 (19M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64.deb’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  19.26M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-15 18:07:58 (169 MB/s) - ‘cloudflared-linux-amd64.deb’ saved [20192500/20192500]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo dpkg -i cloudflared-linux-amd64.deb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAGxt_gtMqi-",
        "outputId": "e2c6ce42-2364-4208-a411-01660985661c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.11.1) ...\n",
            "Setting up cloudflared (2025.11.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which cloudflared\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRziGHTCMtOa",
        "outputId": "a401a10f-43ac-4a5b-94bf-b7497c6c8ce5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/cloudflared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py4JyP9RL2bP",
        "outputId": "6a15333d-28f0-46a8-9ff4-058e2af7453e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/pharma_mas/app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "\n",
        "st.title(\"💊 PharmaMAS — Multi-Agent System (Mock Demo)\")\n",
        "\n",
        "molecule = st.text_input(\"Enter Molecule\", \"Metformin\")\n",
        "\n",
        "if st.button(\"Run Analysis\"):\n",
        "    st.success(f\"Running MAS for: {molecule}\")\n",
        "\n",
        "    st.write(\"📄 Report files will be located here:\")\n",
        "    st.code(\"/content/pharma_mas/reports/\")\n",
        "\n",
        "    st.info(\"Go to the Colab **Files** panel → open `pharma_mas/reports/` → download your PDF & Excel.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjfghKrXL3Ak",
        "outputId": "28bac6fe-59e6-41ef-c435-435c3126be63"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/pharma_mas/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/pharma_mas/app.py --server.port 8501 --server.address 0.0.0.0 &>/content/app.log &\n"
      ],
      "metadata": {
        "id": "-TqV6bv9M2bV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cloudflared tunnel --url http://localhost:8501 --no-autoupdate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hlhTRePL9Hs",
        "outputId": "dbd4dbab-e57f-43c1-9eef-7eb0657d378c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-12-15T18:09:16Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-12-15T18:09:16Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m |  https://impose-supported-portal-version.trycloudflare.com                                 |\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 83ea55259e419549817460d0c097f23ad1327364d0a63fab2c5463b9283251cb)\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update if installed by a package manager.\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: ef27ee89-1507-4982-b9a1-82b337ca005a\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "2025/12/15 18:09:19 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-12-15T18:09:19Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m9b6e8ebb-555f-4d5f-aa36-89c6aa32e18b \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7 \u001b[36mlocation=\u001b[0matl12 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-12-15T18:11:59Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AtVhyjY7L_xD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}